# 爬虫

### 简单爬虫架构

![image-20230907230511917](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20230907230511917.png)

## urllib

### 基本使用

urlopen

```python
from urllib.request import urlopen
url = 'http://www.baidu.com/'
response = urlopen(url)
print(response.read().decode('utf-8'))
```



### 一个类型6个方法

urlopen返回的是一个HTTPResponse类型对象

这个对象含有6个操作方法

```python
response.read() #逐个读取内容，参数为读取长度，不传默认读取全部
response.readline() #读取一行响应内容。参数为读取长度，不传默认读取整行。
response.readlines() #逐行读取响应内容，返回包含所有行的列表。参数为读取长度提示，不传默认读取全部行
response.getcode() #获取响应状态码
response.getheaders() #获取请求头
```

### quote

主要用于确保 URL 中的特殊字符（如空格、斜杠、冒号等）被正确编码，以便在 HTTP 请求中安全传输

#### 语法

```python
urllib.parse.quote(string, safe='/', encoding=None, errors=None)
```

#### 参数

- `string`：要编码的字符串。
- `safe`：一个字符串，其中的字符不会被编码。默认值是 `/`，因为 URL 中的路径部分通常保留斜杠。
- `encoding`：指定编码格式，默认是 UTF-8。
- `errors`：指定编码错误处理方案，默认是 `strict`。

#### 返回值

- 返回编码后的字符串。

1. **指定 `safe` 参数**：

   ```python
   from urllib.parse import quote
   
   string = 'Hello World!'
   encoded_string = quote(string, safe='')
   print(encoded_string)
   ```

   输出：

   ```perl
   Hello%20World%21
   ```
   
   在这个示例中，因为 `safe` 参数是空字符串，所以所有的特殊字符（包括空格和感叹号）都被编码。

2. **编码非 ASCII 字符**：

   ```python
   from urllib.parse import quote
   
   string = '你好'
   encoded_string = quote(string)
   print(encoded_string)
   ```

   输出：

   ```perl
   %E4%BD%A0%E5%A5%BD
   ```
   
   这个示例中，中文字符被编码成了百分号编码的形式。

3. **指定编码格式和错误处理**：

   ```python
   from urllib.parse import quote
   
   string = 'Café'
   encoded_string = quote(string, encoding='utf-8', errors='replace')
   print(encoded_string)
   ```

   输出：

   ```perl
   Caf%C3%A9
   ```

#### 应用场景

1. **URL 参数编码**：当您需要将用户输入的数据作为 URL 参数时，使用 `quote` 可以确保这些数据被正确编码，避免因为特殊字符导致的请求失败。
2. **构建安全的 URL**：在构建 URL 时，使用 `quote` 可以避免注入攻击和其他安全问题。

### unquote

- ```
  urllib.parse.unquote
  ```

  ：用于解码 

  ```
  quote
  ```

   编码的字符串。

  ```python
  from urllib.parse import unquote
  
  encoded_string = 'Hello%20World%21'
  decoded_string = unquote(encoded_string)
  print(decoded_string)
  ```

  输出：

  ```
  Hello World!
  ```

通过使用 `quote` 和 `unquote`，您可以安全地处理 URL 中的字符串，确保它们在传输和解析过程中不会出错。

### 请求头定制

自定义请求头，以满足特定的需求或模拟特定的用户行为。定制请求头，能够控制发送的 HTTP 请求的各个方面。

```python
import urllib.request

url = 'http://www.example.com'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Referer': 'http://www.example.com',
    'Accept-Language': 'en-US,en;q=0.9',
}

# 创建请求对象并添加请求头
request = urllib.request.Request(url, headers=headers)

# 发起请求
response = urllib.request.urlopen(request)

# 处理响应
# ...
```

### 文件下载

urlretrieve()

`urllib.urlretrieve()` 是 Python 标准库 `urllib` 中的一个函数，用于从 URL 中检索（retrieve）远程文件，并将其保存到本地文件系统中。它是一个简单而方便的工具，特别适用于快速下载文件。

#### 语法
```python
urllib.urlretrieve(url, filename=None, reporthook=None, data=None)
```

#### 参数
- `url`：要检索文件的 URL。
- `filename`：要保存文件的路径。如果未提供，则会根据 URL 中的文件名自动推断。
- `reporthook`：可选参数，一个回调函数，在下载过程中会被调用，可以用于显示下载进度。
- `data`：可选参数，如果指定了该参数，则会将其作为请求的数据发送给服务器。常用于 POST 请求。

#### 返回值
返回一个包含 `(filename, headers)` 的元组，其中 `filename` 是保存到本地的文件路径，`headers` 是响应头信息。

#### 示例
```python
import urllib.request

url = 'http://www.example.com/sample.zip'
filename, headers = urllib.request.urlretrieve(url, 'sample.zip')
print("Downloaded file saved as:", filename)
print("Headers:", headers)
```

#### 使用 `reporthook` 显示下载进度
```python
import urllib.request

def progress_hook(count, block_size, total_size):
    percent = int(count * block_size * 100 / total_size)
    print(f"Downloading... {percent}%")

url = 'http://www.example.com/sample.zip'
filename, headers = urllib.request.urlretrieve(url, 'sample.zip', reporthook=progress_hook)
print("Downloaded file saved as:", filename)
```

`progress_hook` 是一个回调函数，它接收三个参数：`count`（已下载的块数）、`block_size`（每个块的大小）、`total_size`（文件总大小）。我们可以利用这些参数来计算并显示下载进度。

#### 注意事项
- 如果 `filename` 参数未提供，`urlretrieve` 会尝试从 URL 中推断出文件名并保存在当前工作目录。
- 使用 `urlretrieve` 下载大文件时可能会占用大量内存，因为它会将整个文件加载到内存中。
- 如果需要更多的控制权和功能，推荐使用 `requests` 库进行文件下载，它提供了更灵活的接口和更好的性能。

### GET 请求

在 HTTP 协议中，GET 请求是用于从服务器获取数据的一种请求方法。在 Python 中，您可以使用 `urllib` 或 `requests` 库来发送 GET 请求。

#### 拼接 URL

当您发送 GET 请求时，通常需要拼接 URL，以包含查询参数。在 Python 中，您可以使用字符串拼接或者更加方便的方式是使用 `urllib.parse.urlencode()` 函数来构建查询字符串。

示例：

```python
from urllib.parse import urlencode

base_url = 'http://www.example.com/search'
params = {
    'q': 'python',
    'page': 1,
    'limit': 10
}

url = base_url + '?' + urlencode(params)
print(url)
```

以上代码会输出：

```
http://www.example.com/search?q=python&page=1&limit=10
```

### POST 请求

在 HTTP 协议中，POST 请求用于向服务器提交数据。与 GET 请求不同，POST 请求通常将数据放在请求体中发送，而不是放在 URL 中。

#### urlencode 和 encode

在发送 POST 请求时，您通常需要将数据编码为 URL 编码格式，并将其放在请求体中发送。在 Python 中，您可以使用 `urllib.parse.urlencode()` 函数来编码数据，并使用 `encode()` 方法将其转换为字节流，以便发送到服务器。

示例：

```python
from urllib.parse import urlencode

data = {
    'username': 'user123',
    'password': 'pass456'
}

encoded_data = urlencode(data)
byte_data = encoded_data.encode('utf-8')  # 将字符串编码为字节流

# 现在 byte_data 可以作为请求体发送到服务器
```

在这个示例中，`data` 字典中的数据被编码为 URL 编码格式，并使用 `encode()` 方法将其转换为字节流。您可以将 `byte_data` 作为请求体发送到服务器，以执行 POST 请求。

### 注意事项

- 在构建 URL 或编码数据时，确保遵循 HTTP 协议的规范和服务器的要求。
- 使用 `urllib.parse.urlencode()` 函数可以方便地构建查询字符串或编码 POST 请求中的数据。
- 在发送 POST 请求时，除了编码数据之外，还需要指定适当的请求头，例如 Content-Type 来告知服务器发送的数据格式。

### cookie登录

在进行 Web 开发时，常常会遇到需要通过 Cookie 进行用户身份验证的情况。Cookie 是服务器发送到客户端并保存在客户端的一小段数据，浏览器在后续的请求中会自动携带该 Cookie，从而实现身份验证等功能。下面是一个使用 Cookie 进行登录验证的基本流程：

#### 1. 发送登录请求获取 Cookie

首先，您需要发送登录请求来获取登录后的 Cookie。通常，这个请求会包含用户的凭证（例如用户名和密码），服务器会验证这些凭证，然后在响应中发送包含用户身份信息的 Cookie。

示例代码（使用 `requests` 库）：

```python
import requests

login_url = 'http://www.example.com/login'
payload = {'username': 'your_username', 'password': 'your_password'}

response = requests.post(login_url, data=payload)

if response.status_code == 200:
    print("Login successful.")
    # 可以从 response.cookies 中获取登录后的 Cookie
    cookies = response.cookies
else:
    print("Login failed.")
```

#### 2. 使用 Cookie 进行后续请求

登录成功后，您可以将获取到的 Cookie 添加到后续的请求中，以实现登录状态的保持。

示例代码：

```python
# 假设您已经有了登录后的 Cookie（在上一步的示例中获取）
# 创建一个会话对象
session = requests.Session()
session.cookies = cookies  # 设置会话的 Cookie

# 发起后续的请求
response = session.get('http://www.example.com/protected_page')

if response.status_code == 200:
    print("Access to protected page successful.")
    # 处理响应...
else:
    print("Access to protected page failed.")
```

在这个示例中，我们使用 `requests` 库创建了一个会话对象，并将登录后获取的 Cookie 设置到了会话中。然后，我们可以使用这个会话对象发送后续的请求，这些请求会自动携带之前设置的 Cookie，从而实现了登录状态的保持。

通过以上步骤，您可以使用 Cookie 实现登录验证，并在登录状态下进行后续的请求。请注意，这只是一个简单的示例，实际情况可能会根据具体的网站和业务逻辑有所不同。

### handler处理器

```python
headers={ 'User-Agent':'...' }
request=urllib.request.Request(url=url,headers=headers)
handler=urllib.request.HTTPHandler()
opener=urllib.request.build_opener(handler)
response=urllib.open(request)
content=response.read().decode('utf-8')
```
`Handler` 处理器是 Python 标准库 `urllib.request` 中用于处理 HTTP 请求和响应的机制之一。它允许您在发送请求和接收响应之前，对请求和响应进行各种定制和处理。

在 Python 中，您可以使用 `urllib.request` 模块提供的各种处理器来构建自定义的请求和响应处理流程，以满足特定的需求。常用的处理器包括：

1. **HTTPHandler**：用于处理 HTTP 请求和响应。
2. **HTTPSHandler**：用于处理 HTTPS 请求和响应。
3. **ProxyHandler**：用于设置代理服务器。
4. **CookieJar**：用于处理 Cookie。
5. **RedirectHandler**：用于处理重定向。

下面是一些常见的用法示例：

#### 1. 使用 `HTTPHandler` 处理器发送 HTTP 请求

```python
import urllib.request

url = 'http://www.example.com'
handler = urllib.request.HTTPHandler()
opener = urllib.request.build_opener(handler)
response = opener.open(url)
content = response.read().decode('utf-8')
```

#### 2. 使用 `ProxyHandler` 设置代理服务器

```python
import urllib.request

proxies = {'http': 'http://proxy.example.com:8080'}
handler = urllib.request.ProxyHandler(proxies)
opener = urllib.request.build_opener(handler)
response = opener.open('http://www.example.com')
content = response.read().decode('utf-8')
```

#### 3. 使用 `CookieJar` 处理器处理 Cookie

```python
import urllib.request
import http.cookiejar

cookie_jar = http.cookiejar.CookieJar()
handler = urllib.request.HTTPCookieProcessor(cookie_jar)
opener = urllib.request.build_opener(handler)

# 发送请求
response = opener.open('http://www.example.com')
# 处理响应中的 Cookie
for cookie in cookie_jar:
    print(cookie.name, cookie.value)
```

通过使用处理器，您可以定制请求和响应的行为，实现各种高级功能，如添加请求头、处理代理、管理 Cookie 等。您还可以根据需要，自定义处理器来实现特定的功能，以满足更复杂的需求。

### urllib代理

当您需要在网络请求中使用代理时，`urllib` 提供了 `ProxyHandler` 处理器，用于设置代理服务器。此外，代理池是一种管理多个代理服务器的机制，用于隐藏客户端的真实 IP 地址，提高请求的成功率和安全性。

```python
proxies = { 'http':'118.24.219.151:16817' }
handler = urllib.request.ProxyHandler(proxies=proxies)
opener = urllib.request.build_opener(handler)

# 使用代理发送请求
response = opener.open('http://www.example.com')
content = response.read().decode('utf-8')
```

### urllib代理池

代理池是一组代理服务器的集合，用于隐藏客户端的真实 IP 地址，提高访问目标网站的成功率和安全性。代理池通常由多个代理服务器组成，客户端可以随机选择一个代理来发送请求，从而实现负载均衡和防止 IP 被封锁。

## xPath

